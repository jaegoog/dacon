{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"koBERT_using_StratifiedKFold_code.ipynb","provenance":[{"file_id":"12hCD7UZ15IxfjW8pNi3uaOq5fGxIxw4X","timestamp":1625800785664},{"file_id":"14qEgegzHqlPAFj8YYtvH79kVzWRSns2Q","timestamp":1625760424590}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"125e0c62fbc443ff8c0a9558c1aee344":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f29c634c9505488b9a0e0ee87e2d66ba","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_740597bea923474c9351b06f5e5a90a1","IPY_MODEL_60e50fa289d040e0adaa2858b35cf272"]}},"f29c634c9505488b9a0e0ee87e2d66ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"740597bea923474c9351b06f5e5a90a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_09b83b0451d040bc994dfab439e1903a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":371391,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":371391,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65f1060e7fa24df98ae558d5828743d3"}},"60e50fa289d040e0adaa2858b35cf272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc37d1cb2c034ffea1bf55b242911d41","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 371k/371k [00:00&lt;00:00, 1.45MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48d0944a9a394cdd879dc825ff6ca756"}},"09b83b0451d040bc994dfab439e1903a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"65f1060e7fa24df98ae558d5828743d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc37d1cb2c034ffea1bf55b242911d41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"48d0944a9a394cdd879dc825ff6ca756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee2a3d20674a4abcadf75e7708541ff4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_508bb1a0c9944545a5669f517db28a68","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b41af7f49a874ba5b6ccf993028dcc01","IPY_MODEL_e3cca2df14ae4fcdba547e4ab9954235"]}},"508bb1a0c9944545a5669f517db28a68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b41af7f49a874ba5b6ccf993028dcc01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e151f1a5d0764486baccf8d545bf9200","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":77779,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77779,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_daa1f086c1e247679c966b7343a9d7ec"}},"e3cca2df14ae4fcdba547e4ab9954235":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ae72c1e6fb07467cb6e6726a60f10104","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 77.8k/77.8k [00:46&lt;00:00, 1.69kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8a25a94ec4e4ffdbeac759ca6164e77"}},"e151f1a5d0764486baccf8d545bf9200":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"daa1f086c1e247679c966b7343a9d7ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae72c1e6fb07467cb6e6726a60f10104":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8a25a94ec4e4ffdbeac759ca6164e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"032cec71f6c04bbd8b01c7e4b70f1e40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0d4d901915324b2894f9d88c7d770acd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b598268699e45d5982833ea999af324","IPY_MODEL_2772cae87a49472c9b9ea441897833e9"]}},"0d4d901915324b2894f9d88c7d770acd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b598268699e45d5982833ea999af324":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_903d7a55adfd4f848b92dfca0058d585","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":426,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":426,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41d299c83e2f48669d48004f0db464e1"}},"2772cae87a49472c9b9ea441897833e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c6c173925104fddbe0baf0f406c56f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426/426 [00:07&lt;00:00, 53.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f08985bf05e43599ae20af80af7a596"}},"903d7a55adfd4f848b92dfca0058d585":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"41d299c83e2f48669d48004f0db464e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c6c173925104fddbe0baf0f406c56f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f08985bf05e43599ae20af80af7a596":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28d72a44f1a14ef9996756f062d4402d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a254f57f772d40b681ad0633dc2b9823","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f8cd0e657ebc45239b96ef423d436e08","IPY_MODEL_402490faeafb433598719fbb22792dcf"]}},"a254f57f772d40b681ad0633dc2b9823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8cd0e657ebc45239b96ef423d436e08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5a75bb9499bc4576bc5083ecaa5ac358","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":368792146,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":368792146,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13a195e064174f96864b686f98f3205c"}},"402490faeafb433598719fbb22792dcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3bc8f9c257a9432b8a1d05f4f47ba6ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 369M/369M [00:07&lt;00:00, 48.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3821e56fd8e84d38bb0ea8a2fe6e81a8"}},"5a75bb9499bc4576bc5083ecaa5ac358":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"13a195e064174f96864b686f98f3205c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bc8f9c257a9432b8a1d05f4f47ba6ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3821e56fd8e84d38bb0ea8a2fe6e81a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"o4_TL4kq46dk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PBndWx8O0f0b"},"source":["# TPU를 사용하기 위한 설정"]},{"cell_type":"code","metadata":{"id":"9KcVBoMZlTzv"},"source":["# BERT는 colab TPU로 학습해야 시간이 덜 걸림"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpctL--8l1P7"},"source":["# #  TPU초기 설정\n","# import tensorflow as tf\n","# import os\n","\n","# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","\n","# tf.config.experimental_connect_to_cluster(resolver)\n","# tf.tpu.experimental.initialize_tpu_system(resolver)\n","\n","# strategy = tf.distribute.TPUStrategy(resolver)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5HAji7s04eRe","executionInfo":{"status":"ok","timestamp":1625800950494,"user_tz":-540,"elapsed":17395,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"69465e8a-6272-449c-d692-1fae8b8d09e0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VRoBgQfW3EMp"},"source":["# 기본 구성"]},{"cell_type":"code","metadata":{"id":"9V1puuSQM_BU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625800062418,"user_tz":-540,"elapsed":3011,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"1fc60e9f-14ed-4687-cf4c-ea8d659254b6"},"source":["pip install wordcloud"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwOSDp_CpVOo","executionInfo":{"status":"ok","timestamp":1625800068647,"user_tz":-540,"elapsed":6232,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"6e7cd7e5-133f-4567-e428-ba3d5f4bfdce"},"source":["pip install hanja # 한자 분류 모듈"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hanja\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/97/ce51b5c771e7c9a673568232125e587cbc378ff1dd13057f237bedcd71e8/hanja-0.13.3.tar.gz (120kB)\n","\u001b[K     |████████████████████████████████| 122kB 6.8MB/s \n","\u001b[?25hCollecting pyyaml==5.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n","\u001b[K     |████████████████████████████████| 266kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from hanja) (3.6.4)\n","Collecting pytest-cov\n","  Downloading https://files.pythonhosted.org/packages/ba/84/576b071aef9ac9301e5c0ff35d117e12db50b87da6f12e745e9c5f745cc2/pytest_cov-2.12.1-py2.py3-none-any.whl\n","Requirement already satisfied: coveralls in /usr/local/lib/python3.7/dist-packages (from hanja) (0.5)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.10.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (8.8.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (57.0.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.15.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (21.2.0)\n","Collecting coverage>=5.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/e0/fc9f7bd9b84e6b41d0aad1a113e36714aac0c0a9b307aca5f9af443bc50f/coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242kB)\n","\u001b[K     |████████████████████████████████| 245kB 13.2MB/s \n","\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest-cov->hanja) (0.10.2)\n","Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (2.23.0)\n","Requirement already satisfied: docopt>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (0.6.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (1.24.3)\n","Building wheels for collected packages: hanja, pyyaml\n","  Building wheel for hanja (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hanja: filename=hanja-0.13.3-cp37-none-any.whl size=128426 sha256=3cfcb9e12ac95cfbb19bb3edfec33a3ee7a93c80bc920c58609528159b80de45\n","  Stored in directory: /root/.cache/pip/wheels/45/fc/c9/b7e7cb5c86935a1a99e2ad07f763728f8f17560e7b815a4b27\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp37-cp37m-linux_x86_64.whl size=44117 sha256=4ff338c866497d7c3d474808f564a265f9dae0c08de1bdc94e1df8da4b4d3ece\n","  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n","Successfully built hanja pyyaml\n","\u001b[31mERROR: datascience 0.10.6 has requirement coverage==3.7.1, but you'll have coverage 5.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: coveralls 0.5 has requirement coverage<3.999,>=3.6, but you'll have coverage 5.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pytest-cov 2.12.1 has requirement pytest>=4.6, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n","Installing collected packages: pyyaml, coverage, pytest-cov, hanja\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: coverage 3.7.1\n","    Uninstalling coverage-3.7.1:\n","      Successfully uninstalled coverage-3.7.1\n","Successfully installed coverage-5.5 hanja-0.13.3 pytest-cov-2.12.1 pyyaml-5.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v2I05CaDmnx-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625800073415,"user_tz":-540,"elapsed":4774,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"ff68dd2c-7f27-456f-ae3f-e13b7add1f79"},"source":["# !pip install transformers\n","!pip install transformers==3.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (3.0.12)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 40.8MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 51.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 45.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (1.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (3.0.4)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fw3VANV4Nu9C","executionInfo":{"status":"ok","timestamp":1625800073416,"user_tz":-540,"elapsed":19,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"3d81e663-b5f7-487c-daf5-f41ae043ee24"},"source":[" !nvidia-smi "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Jul  9 03:07:53 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H9r4pVsjrhqy"},"source":["# pip install kobart-transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzxIbpTpvr6G"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import json\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","import seaborn as sns\n","\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from tensorflow.keras.models import clone_model\n","\n","from tqdm import tqdm\n","\n","import hanja\n","from hanja import hangul\n","\n","from transformers import *\n","# from transformers import BertTokenizer, TFBertModel,PreTrainedTokenizerFast, TFBartModel\n","# from kobart_transformers import get_kobart_tokenizer, get_kobart_model\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences #tensorflow 전처리 모듈1\n","from tensorflow.keras.preprocessing.text import Tokenizer #tensorflow 전처리 모듈2\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# 그래프를 출력창에서 바로 볼 수 있게함\n","%matplotlib inline \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8CQTERKv-j2"},"source":["train = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/train_data.csv\", error_bad_lines=False  )\n","test = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/test_data.csv\",error_bad_lines=False)\n","submission = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/sample_submission.csv\",error_bad_lines=False)\n","topic_dict = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/topic_dict.csv\",error_bad_lines=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YC0oNgaelk4L"},"source":["# BERT를 이용한 NEWS Topic 분류"]},{"cell_type":"markdown","metadata":{"id":"cH26NSFjxbPB"},"source":["### EDA"]},{"cell_type":"code","metadata":{"id":"3AmgkdPb482G"},"source":["import logging\n","import os\n","import unicodedata\n","from shutil import copyfile\n"," \n","from transformers import PreTrainedTokenizer\n"," \n"," \n","logger = logging.getLogger(__name__)\n"," \n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n","                     \"vocab_txt\": \"vocab.txt\"}\n"," \n","PRETRAINED_VOCAB_FILES_MAP = {\n","    \"vocab_file\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n","    },\n","    \"vocab_txt\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n","    }\n","}\n"," \n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n","    \"monologg/kobert\": 512,\n","    \"monologg/kobert-lm\": 512,\n","    \"monologg/distilkobert\": 512\n","}\n"," \n","PRETRAINED_INIT_CONFIGURATION = {\n","    \"monologg/kobert\": {\"do_lower_case\": False},\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\n","}\n"," \n","SPIECE_UNDERLINE = u'▁'\n"," \n"," \n","class KoBertTokenizer(PreTrainedTokenizer):\n","    \"\"\"\n","        SentencePiece based tokenizer. Peculiarities:\n","            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n","    \"\"\"\n","    vocab_files_names = VOCAB_FILES_NAMES\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n"," \n","    def __init__(\n","            self,\n","            vocab_file,\n","            vocab_txt,\n","            do_lower_case=False,\n","            remove_space=True,\n","            keep_accents=False,\n","            unk_token=\"[UNK]\",\n","            sep_token=\"[SEP]\",\n","            pad_token=\"[PAD]\",\n","            cls_token=\"[CLS]\",\n","            mask_token=\"[MASK]\",\n","            **kwargs):\n","        super().__init__(\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            pad_token=pad_token,\n","            cls_token=cls_token,\n","            mask_token=mask_token,\n","            **kwargs\n","        )\n"," \n","        # Build vocab\n","        self.token2idx = dict()\n","        self.idx2token = []\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\n","            for idx, token in enumerate(f):\n","                token = token.strip()\n","                self.token2idx[token] = idx\n","                self.idx2token.append(token)\n"," \n","        self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n","        self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n"," \n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n"," \n","        self.do_lower_case = do_lower_case\n","        self.remove_space = remove_space\n","        self.keep_accents = keep_accents\n","        self.vocab_file = vocab_file\n","        self.vocab_txt = vocab_txt\n"," \n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n"," \n","    @property\n","    def vocab_size(self):\n","        return len(self.idx2token)\n"," \n","    def __getstate__(self):\n","        state = self.__dict__.copy()\n","        state[\"sp_model\"] = None\n","        return state\n"," \n","    def __setstate__(self, d):\n","        self.__dict__ = d\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(self.vocab_file)\n"," \n","    def preprocess_text(self, inputs):\n","        if self.remove_space:\n","            outputs = \" \".join(inputs.strip().split())\n","        else:\n","            outputs = inputs\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n"," \n","        if not self.keep_accents:\n","            outputs = unicodedata.normalize('NFKD', outputs)\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n","        if self.do_lower_case:\n","            outputs = outputs.lower()\n"," \n","        return outputs\n"," \n","    def _tokenize(self, text, return_unicode=True, sample=False):\n","        \"\"\" Tokenize a string. \"\"\"\n","        text = self.preprocess_text(text)\n"," \n","        if not sample:\n","            pieces = self.sp_model.EncodeAsPieces(text)\n","        else:\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n","        new_pieces = []\n","        for piece in pieces:\n","            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n","                    if len(cur_pieces[0]) == 1:\n","                        cur_pieces = cur_pieces[1:]\n","                    else:\n","                        cur_pieces[0] = cur_pieces[0][1:]\n","                cur_pieces.append(piece[-1])\n","                new_pieces.extend(cur_pieces)\n","            else:\n","                new_pieces.append(piece)\n"," \n","        return new_pieces\n"," \n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\n"," \n","    def _convert_id_to_token(self, index, return_unicode=True):\n","        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n","        return self.idx2token[index]\n"," \n","    def convert_tokens_to_string(self, tokens):\n","        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n","        return out_string\n"," \n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n","        by concatenating and adding special tokens.\n","        A RoBERTa sequence has the following format:\n","            single sequence: [CLS] X [SEP]\n","            pair of sequences: [CLS] A [SEP] B [SEP]\n","        \"\"\"\n","        if token_ids_1 is None:\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        sep = [self.sep_token_id]\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\n"," \n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n","        \"\"\"\n","        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n","        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n","        Args:\n","            token_ids_0: list of ids (must not contain special tokens)\n","            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n","                for sequence pairs\n","            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n","                special tokens for the model\n","        Returns:\n","            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n","        \"\"\"\n"," \n","        if already_has_special_tokens:\n","            if token_ids_1 is not None:\n","                raise ValueError(\n","                    \"You should not supply a second sequence if the provided sequence of \"\n","                    \"ids is already formated with special tokens for the model.\"\n","                )\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n"," \n","        if token_ids_1 is not None:\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n","        return [1] + ([0] * len(token_ids_0)) + [1]\n"," \n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n","        A BERT sequence pair mask has the following format:\n","        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n","        | first sequence    | second sequence\n","        if token_ids_1 is None, only returns the first portion of the mask (0's).\n","        \"\"\"\n","        sep = [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        if token_ids_1 is None:\n","            return len(cls + token_ids_0 + sep) * [0]\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n"," \n","    def save_vocabulary(self, save_directory):\n","        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n","            to a directory.\n","        \"\"\"\n","        if not os.path.isdir(save_directory):\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n","            return\n"," \n","        # 1. Save sentencepiece model\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n"," \n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n","            copyfile(self.vocab_file, out_vocab_model)\n"," \n","        # 2. Save vocab.txt\n","        index = 0\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n","                if index != token_index:\n","                    logger.warning(\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n","                    )\n","                    index = token_index\n","                writer.write(token + \"\\n\")\n","                index += 1\n"," \n","        return out_vocab_model, out_vocab_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeteJ2oBJtDQ"},"source":["def clean_text(texts):\n","    corpus = []\n","    texts = texts.replace(\"日\",\"일본\")\n","    texts = texts.replace(\"美\",\"미국\")\n","    texts = texts.replace(\"北\",\"북한\")\n","    texts = texts.replace(\"英\",\"영국\")\n","    texts = texts.replace(\"中\",\"중국\")\n","    texts = texts.replace(\"與\",\"여당\")\n","    texts = texts.replace(\"靑\",\"청와대\")\n","    texts = texts.replace(\"野\",\"야당\")\n","    texts = texts.replace(\"伊\",\"이탈리아\")\n","    texts = texts.replace(\"韓\",\"한국\")\n","    texts = texts.replace(\"南\",\"한국\")\n","    texts = texts.replace(\"獨\",\"독일\")\n","    texts = texts.replace(\"佛\",\"프랑스\")\n","    texts = texts.replace(\"檢\",\"검찰\")\n","    texts = texts.replace(\"銀\",\"은행\")\n","    for i in range(0, len(texts)):\n","        \n","        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(texts[i])) #remove punctuation\n","        review = re.sub(r'\\d+','', str(texts[i]))# remove number\n","        review = review.lower() #lower case\n","        review = re.sub(r'\\s+', ' ', review) #remove extra space\n","        review = re.sub(r'<[^>]+>','',review) #remove Html tags\n","        review = re.sub(r'\\s+', ' ', review) #remove spaces\n","        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n","        review = re.sub(r'\\s+$', '', review) #remove space from the end\n","        review = re.sub(\"[一-龥]\",'', review) # remove hanja\n","        corpus.append(review)\n","    return corpus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8eyZF_X1Zzc"},"source":["train.title = clean_text(train.title)\n","test.title = clean_text(test.title)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPj6TBCou3rO","executionInfo":{"status":"ok","timestamp":1625800140690,"user_tz":-540,"elapsed":11,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"4fa935a8-65e8-4376-9e6d-e185d0286073"},"source":["train_data_text = list(train['title'])\n","\n","train_clear_text = []\n","\n","for i in tqdm(range(len(train_data_text))):\n","  train_clear_text.append(str(train_data_text[i]).replace('\\\\n', ''))\n","train['clear_title'] = train_clear_text\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 45654/45654 [00:00<00:00, 1310888.69it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Jyt3Vss7vwy0"},"source":["train_clear_text = list(train['clear_title'])\n","\n","train_clear_text2 = []\n","\n","for text in train_clear_text:\n","  temp = re.sub('[-=+,#:;//●<>▲\\?:^$.☆!★()Ⅰ@*\\\"※~>`\\'…》→←]', ' ', text)\n","  train_clear_text2.append(temp)\n","train['clear_title'] = train_clear_text2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_1VvHXXwE54","executionInfo":{"status":"ok","timestamp":1625800140690,"user_tz":-540,"elapsed":7,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"52591850-2468-4b65-b1df-05558082b9f9"},"source":["test_data_text = list(test['title'])\n","\n","test_clear_text = []\n","\n","for i in tqdm(range(len(test_data_text))):\n","  test_clear_text.append(test_data_text[i].replace('\\\\n', ' '))\n","test['clear_title'] = test_clear_text\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 9131/9131 [00:00<00:00, 1703353.04it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hvg85fHcwGYg"},"source":["test_clear_text = list(test['clear_title'])\n","\n","test_clear_text2 = []\n","\n","for text in test_clear_text:\n","  temp = re.sub('[-=+,#:;//●<>▲\\?:^$.☆!★()Ⅰ@*\\\"※~>`\\'…》→←]', ' ', text)\n","  test_clear_text2.append(temp)\n","test['clear_title'] = test_clear_text2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9h1CXo8yIHu","executionInfo":{"status":"ok","timestamp":1625800142051,"user_tz":-540,"elapsed":2,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"c97153e1-5812-46e4-85f1-65153a614cb5"},"source":["train['clear_title']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0               인천 핀란드 항공기 결항 휴가철 여행객 분통\n","1            실리콘밸리 넘어서겠다 구글 조원 들여 전역 거점화\n","2         이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것\n","3        nyt 클린턴 측근기업 특수관계 조명 공과 사 맞물려종합\n","4              시진핑 트럼프에 중미 무역협상 조속 타결 희망\n","                      ...               \n","45649       kb금융 미국 ib 스티펠과 제휴 선진국 시장 공략\n","45650     보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토\n","45651             게시판 키움증권 키움 영웅전 실전투자대회\n","45652                  답변하는 배기동 국립중앙박물관장\n","45653       한국인터넷기자상 시상식 내달 일 개최 특별상 김성후\n","Name: clear_title, Length: 45654, dtype: object"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178,"referenced_widgets":["125e0c62fbc443ff8c0a9558c1aee344","f29c634c9505488b9a0e0ee87e2d66ba","740597bea923474c9351b06f5e5a90a1","60e50fa289d040e0adaa2858b35cf272","09b83b0451d040bc994dfab439e1903a","65f1060e7fa24df98ae558d5828743d3","fc37d1cb2c034ffea1bf55b242911d41","48d0944a9a394cdd879dc825ff6ca756","ee2a3d20674a4abcadf75e7708541ff4","508bb1a0c9944545a5669f517db28a68","b41af7f49a874ba5b6ccf993028dcc01","e3cca2df14ae4fcdba547e4ab9954235","e151f1a5d0764486baccf8d545bf9200","daa1f086c1e247679c966b7343a9d7ec","ae72c1e6fb07467cb6e6726a60f10104","e8a25a94ec4e4ffdbeac759ca6164e77"]},"id":"4bYfpXXE5Tea","executionInfo":{"status":"ok","timestamp":1625800144819,"user_tz":-540,"elapsed":1669,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"c9590c1b-71f7-4e8a-b3ab-22165069288c"},"source":["tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"125e0c62fbc443ff8c0a9558c1aee344","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee2a3d20674a4abcadf75e7708541ff4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1321: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n","Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2YqTZBolw3HL"},"source":["model_name = 'monologg/kobert'\n","SEED_NUM = 977\n","tf.random.set_seed(SEED_NUM)\n","np.random.seed(SEED_NUM)\n","BATCH_SIZE = 50\n","NUM_EPOCHS = 20\n","VALID_SPLIT = 0.2\n","MAX_LEN = 30\n","NUM_CLASS = 7\n","K_SPLIT = 3\n","# 이상치 데이터로인해 평균이 급격히 올라갈수 있기에 EDA분석을 통해 적절히 정해야함 평균값이던 중간값이던 3사분위 값이던\n","# EDA를 통해 이상치 데이터가 없으면 최대값이용"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_xHB5wRmoS9"},"source":["\n","\n","# BERT에 필요한 입력값은 총 3개\n","# input_ids : 문장을 tokenize해서 index로 변환\n","# attention_mask : 1은 attention에 영향을 받음, 0은 영향을 받지 않음\n","# token_type_ids : 0과 1로 문장의 토큰 값을 분리\n","\n","# special token 역할\n","# [UNK] : 모르는 단어에 대한 token\n","# [MASK] : 마스크 token, 사전학습(Pre-training)에서 활용\n","# [PAD] : 최대 길이를 맞추는 용도\n","# [SEP] : 문장의 종결을 알림\n","# [CLS] : 문장의 시작을 알림\n","\n","def bert_tokenizer(sent, MAX_LEN):\n","\n","    encoded_dict = tokenizer.encode_plus(\n","        \n","        text = sent,\n","        add_special_tokens = True, # True : 토큰 시작점에 [CLS] 토큰과 토큰의 마지막에 [SEP]토큰을 붙임\n","        max_length = MAX_LEN, # MAX_LEN 최대 길이에 따라 문장의 길이를 맞추는 작업을 진행 ; MAX_LEN보다 길면 truncate\n","        pad_to_max_length = True, # True : MAX_LEN의 길이에 미치지 못하는 문장에 padding을 적용 **padding : 길이를 일괄적으로 맞춰주는 것\n","                                                     # 각 데이터의 길이가 다를경우 모델에 적용할 수 없음 그렇기에 padding진행\n","                                         \n","        return_attention_mask = True, # True : BERT에 필요한 입력값 중 attention_mask를 생성\n","        truncation = True \n","        # encoded_plus 과정 중 token_type으로 문장이 1개면 0, 문장이 2개면 0과 1로 구분\n","    )\n","\n","\n","    input_id = encoded_dict['input_ids'] # BERT 입력값 중 하나인 input_ids\n","    attention_mask = encoded_dict['attention_mask'] # attention_mask ; 단순히 padding과 non-padding을 구분\n","    token_type_id = encoded_dict['token_type_ids'] # 두개의 문장 구분용\n","\n","\n","    return input_id, attention_mask, token_type_id # 각각의 BERT 입력값들을 encoded_dict를 한 결과를 return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l9u8sDob0RJv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625791620752,"user_tz":-540,"elapsed":3,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"0757c1f1-208e-4af6-c680-164489e18d75"},"source":["print(tokenizer.all_special_tokens) # BERT special tokens\n","print(tokenizer.all_special_ids)  # BERT special tokens의 index"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n","[0, 3, 1, 2, 4]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h0vDMmjV4OkA"},"source":["def get_kfold_sets(train, k=5):\n","    kf = KFold(n_splits=k, shuffle=True)\n","    for train_texts, train_labels in kf.split(train.text.values, train.target.values):\n","        train_texts, valid_texts, train_labels, valid_labels = train_test_split(train.text.values, train.target.values, test_size=0.2)\n","        train_input = bert_encode(train_texts, tokenizer, max_len=token_max_len)\n","        valid_input = bert_encode(valid_texts, tokenizer, max_len=token_max_len)\n","        \n","        yield train_input, train_labels, valid_input, valid_labels\n","\n","def get_train_sets(train):\n","    train_input = bert_encode(train.text.values, tokenizer, max_len=token_max_len)\n","    train_labels = train.target.values\n","    \n","    return train_input, train_labels\n","\n","\n","\"\"\"\n","\n","Model cloning is similar to calling a model on new inputs, except that it creates new layers (and thus new weights) instead of sharing the weights of the existing layers.\n","\n","\"\"\"\n","\n","def cross_val_score(train, k=3, epochs=10, batch_size=16):\n","    f1_vals = []\n","    models = []\n","    i = 0\n","    for train_input, train_labels, valid_input, valid_labels in get_kfold_sets(train, k=k):\n","\n","        model = clone_model(model_template)\n","\n","        model.compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])\n","        \n","        train_history = model.fit(\n","            train_input, train_labels,\n","            validation_data=(valid_input, valid_labels),\n","            epochs=epochs,\n","            batch_size=batch_size,\n","            callbacks=[EarlyStopping(patience=1, monitor='val_mse', mode='min', verbose=True)]\n","        )\n","        \n","        pred = model.predict(valid_input)\n","        f1_val = f1_score(valid_labels, np.round(pred))\n","        print(f'f1-val: {f1_val}')\n","        f1_vals.append(f1_val)\n","        models.append(model)\n","        df = pd.DataFrame(train_history.history)\n","        df['f1-val'] = f1_val\n","        df.to_csv(f'history_{i}.csv')\n","        i += 1\n","    return np.array(f1_vals).mean(), models\n","\n","k = 5\n","f1_val, models = cross_val_score(train['clean_text'], k=k)\n","print(f'f1-mean: {f1_val}')\n","\n","\n","\n","def get_model(bert_layer, max_len=max_len):\n","    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","\n","    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    clf_output = sequence_output[:, 0, :]\n","    x = Dense(256, activation='relu')(clf_output)\n","    out = Dense(n_class, activation='softmax')(x)\n","    \n","    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n","    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","    \n","    return model\n","\n","\n","\n","cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n","\n","\n","\n","p_val = np.zeros((trn[0].shape[0], n_class))\n","p_tst = np.zeros((tst[0].shape[0], n_class))\n","for i, (i_trn, i_val) in enumerate(cv.split(trn[0], y), 1):\n","    print(f'training model for CV #{i}')\n","    es = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=2,\n","                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n","    \n","    clf = get_model(bert_layer, max_len=max_len)\n","    if i == 1:\n","        print(clf.summary())\n","        \n","    clf.fit([x[i_trn] for x in trn], \n","            to_categorical(y[i_trn]),\n","            validation_data=([x[i_val] for x in trn], to_categorical(y[i_val])),\n","            epochs=10,\n","            batch_size=8,\n","            callbacks=[es])\n","    p_val[i_val, :] = clf.predict([x[i_val] for x in trn])\n","    p_tst += clf.predict(tst) / n_fold\n","    \n","    del clf\n","    clear_session()\n","    gc.collect()\n","\n","\n","print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n","print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9ECQnRilqoh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625791629798,"user_tz":-540,"elapsed":7647,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"02ea3285-d221-41fc-f723-284830252c41"},"source":["\n","input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","train_data_labels = []\n","\n","# bert_tokenizer를 이용하여 encoding진행\n","for train_sent, train_label in tqdm(zip(train[\"clear_title\"], train[\"topic_idx\"])): \n","    try:\n","\n","        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        train_data_labels.append(train_label)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(train_sent)\n","        pass\n","\n","\n","train_news_input_ids = np.array(input_ids, dtype=int)\n","train_news_attention_masks = np.array(attention_masks, dtype=int)\n","train_news_type_ids = np.array(token_type_ids, dtype=int)\n","\n","# 최종 출력값은 numpy로 변환한 후 tuple 형태로 묶어서 저장\n","train_news_inputs = (train_news_input_ids, train_news_attention_masks, train_news_type_ids)\n","\n","train_data_labels = np.asarray(train_data_labels, dtype=np.int32) # 정답 tokenizing 리스트\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","45654it [00:07, 6469.86it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mJJFYoB4oSG1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625791631208,"user_tz":-540,"elapsed":360,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"3e4fd3f4-6a7c-413e-f350-45890b3ffb41"},"source":["# bert_tokenizer를 통해 실제결과가 나오는지 테스트\n","INPUT_id = train_news_input_ids[30]\n","ATTENTION_mask = train_news_attention_masks[30]\n","TOKEN_TYPE_id = train_news_type_ids[30]\n","\n","print(INPUT_id)\n","print(ATTENTION_mask)\n","print(TOKEN_TYPE_id)\n","print(tokenizer.decode(INPUT_id))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[   2  517 6605 7096 7565 2643 6150  517  367  398  382 5163 4841 6853\n"," 2268 4519 7979 1133 7438 7328 7053    3    1    1    1    1    1    1\n","    1    1]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","[CLS] 셰이크 살만 afc 회장 평양 방문 최휘 국가체육지도위원장[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8xD_SLf4o_rY","colab":{"base_uri":"https://localhost:8080/","height":178,"referenced_widgets":["032cec71f6c04bbd8b01c7e4b70f1e40","0d4d901915324b2894f9d88c7d770acd","7b598268699e45d5982833ea999af324","2772cae87a49472c9b9ea441897833e9","903d7a55adfd4f848b92dfca0058d585","41d299c83e2f48669d48004f0db464e1","3c6c173925104fddbe0baf0f406c56f8","6f08985bf05e43599ae20af80af7a596","28d72a44f1a14ef9996756f062d4402d","a254f57f772d40b681ad0633dc2b9823","f8cd0e657ebc45239b96ef423d436e08","402490faeafb433598719fbb22792dcf","5a75bb9499bc4576bc5083ecaa5ac358","13a195e064174f96864b686f98f3205c","3bc8f9c257a9432b8a1d05f4f47ba6ba","3821e56fd8e84d38bb0ea8a2fe6e81a8"]},"executionInfo":{"status":"ok","timestamp":1625791652209,"user_tz":-540,"elapsed":18409,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"ea1deed9-43d9-4518-fee3-e0565715ec37"},"source":["class TFBertClassifier(tf.keras.Model): # pre_trained된 bert model을 불러와 그 위에 완전연결층 1층을 쌓은 구조\n","                                                              # class로 모델을 구현하려면 tf.keras.Model을 상속받아야 함\n","    # TFBertClassifier생성할 때마다 __init__실행                                                          \n","    def __init__(self, model_name, dir_path, num_class): # model_name : 인자로 받아 활용할 모델 이름, dir_path : 모델이 저장된 위치\n","                                                                                            # num_class : 원하는 정답의 개수(감성분석인 경우 2; 긍정, 부정)\n","        # super함수를 통해 부모 클래스(tf.keras.Model)에 있는 __init__함수 호출   \n","        # tf.keras.Model 클래스를 상속받는 경우 super함수를 통해 부모 클래스에 __init__ 함수의 인자에 모델이름을 전달하면\n","        # tf.keras.Model을 상속받은 모든 자식은 해당 모델의 이름으로 공통적으로 사용\n","        super(TFBertClassifier, self).__init__()\n","\n","         \n","        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True) # 기존에 pre_trained 한 부분이 로드됨\n","                                                                                                                                    \n","        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob) # 과적합을 방지하기 위한 layer\n","        # self.classifier을 통해 topic_idx를 전부 분류\n","        self.classifier = tf.keras.layers.Dense(num_class,\n","                                                                    kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n","                                                                    name=\"classifier\")  # 완전연결층 1층\n","\n","\n","    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False): \n","        #__init__에서 선언한 내용을 실제 입력을 받고 실행하는 call 메서드임\n","        # call함수를 호출하면 입력한 inputs을 통해 마지막에 예측값을 출력\n","        # 영화 리뷰 text를 inputs을 통해 받음\n","        \n","\n","        # output 값 : sequence_output, pooled_output, (hidden_states), (attentions)\n","        # sequence_output : sequence 길이의 출력을 모두 입력으로 받음; 이 벡터의 차원 ' 임베딩 크기 * 최대문장길이'\n","        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids) # bert를 통해 outputs로 결과값을 추출\n","        pooled_output = outputs[1] # pooled_output\n","        pooled_output = self.dropout(pooled_output, training=training)\n","        logits = self.classifier(pooled_output) # self.classifier를 통해 완전연결층을 활용하여 최종적으로 self.num_labels 개수에 맞는 예측값을 출력\n","\n","        return logits\n","\n","cls_model = TFBertClassifier(model_name=model_name,\n","                                                dir_path='bert_ckpt', # ???\n","                                                num_class=NUM_CLASS) # num_class 바꿔야함\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"032cec71f6c04bbd8b01c7e4b70f1e40","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=426.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28d72a44f1a14ef9996756f062d4402d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=368792146.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"j3_GmLuU4M2l"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ec3RNG4kueni"},"source":["### Adam최적화와 손실값, 모델 정확도 정의"]},{"cell_type":"code","metadata":{"id":"Jcs1-P5Ot92d"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","cls_model.compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DvDK6ghupe0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625791665151,"user_tz":-540,"elapsed":248,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"f3e32d27-0238-42f1-f6a8-c74932887b99"},"source":["# 모델이 어느 시점이 되면 학습평가점수는 높아지는데 검증평가 점수가 낮아지는 overfitting현상이 발생하거나\n","# 학습도중 특정 상태의 모델에서 하이퍼파라미터를 바꿔서 다시 학습을 진행할 수도 있음\n","# => tensowflow.keras.callback 모듈의 EarlyStopping, ModelCheckpoint 클래스를 활용하여 해결\n","\n","\n","# 특정 epoch에서 현재 검증 평가 점수가 이전 검증 평가 점수보다 일정수치 미만으로 낮아지면 학습을 멈추는 역할\n","# 학습 중 overfitting을 방지한다는 것\n","es_callback = EarlyStopping(\n","                                monitor='val_accuracy', # 'val_accuracy'를 통해 검증 평가 점수로 활용한다는 것\n","                                mode='max',\n","                                min_delta=0.0001, # 활용한 평가 점수에 따라 현재 점수가 이전 점수에 비해 0.0001 보다 낮아지면 overfitting현상이 발생한다고 생각하고 학습을 멈춤\n","                                patience=4,\n","                                baseline=0.4\n","                                 ) # 검증 평가 점수가 이전 최고 점수보다 높아지지 않는 epoch수가 patience에 입력한 횟수를 넘어가면 학습을 멈춤\n","\n","# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n","# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n","\n","\n","\n","DATA_OUT_PATH = '/content/drive/MyDrive/best_model'\n","# 오류시 DATA_OUT_PATH = '/content/gdrive/MyDrive/bert_data_out'\n","\n","checkpoint_path = DATA_OUT_PATH +  '/best_modeling.h5'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create path if exists\n","if os.path.exists(checkpoint_dir):\n","    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","# Epoch마다 모델을 저장하게끔 함(학습중 모델을 저장한다는 것)    \n","cp_callback = ModelCheckpoint(\n","    checkpoint_path, \n","    monitor='val_accuracy', # save_best_only를 하는 평가기준\n","    verbose=1, \n","    save_best_only=True, # True : 가장 성능이 좋은 모델만 저장한다는 것\n","    save_weights_only=False # True : 모델 그래프를 전부 저장하는 것이 아닌 모델 가중치만 저장한다는 것\n","    )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/best_model -- Folder already exists \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d_VxlFjOAC1h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625793168261,"user_tz":-540,"elapsed":1484962,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"adf54798-2e20-4e70-d7b2-2bb4a10d0d6b"},"source":["\n","# 학습과 eval 시작\n","history = cls_model.fit(train_news_inputs, train_data_labels, \n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        validation_split = VALID_SPLIT, # 학습데이터에서 일정한 비율로 무작위로 나눔\n","                        callbacks=[es_callback, cp_callback]\n","                        ) # 검증데이터셋이 있을경우 파라미터로 validation_data = 로 데이터셋을 지정한 다음 validation_split파라미터를 지운다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","731/731 [==============================] - 259s 333ms/step - loss: 0.5240 - accuracy: 0.8292 - val_loss: 0.5343 - val_accuracy: 0.8157\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.81568, saving model to /content/drive/MyDrive/best_model/best_modeling.h5\n","Epoch 2/20\n","731/731 [==============================] - 244s 334ms/step - loss: 0.3308 - accuracy: 0.8897 - val_loss: 0.4603 - val_accuracy: 0.8391\n","\n","Epoch 00002: val_accuracy improved from 0.81568 to 0.83912, saving model to /content/drive/MyDrive/best_model/best_modeling.h5\n","Epoch 3/20\n","731/731 [==============================] - 244s 334ms/step - loss: 0.2547 - accuracy: 0.9156 - val_loss: 0.4794 - val_accuracy: 0.8369\n","\n","Epoch 00003: val_accuracy did not improve from 0.83912\n","Epoch 4/20\n","731/731 [==============================] - 244s 333ms/step - loss: 0.1964 - accuracy: 0.9359 - val_loss: 0.5501 - val_accuracy: 0.8321\n","\n","Epoch 00004: val_accuracy did not improve from 0.83912\n","Epoch 5/20\n","731/731 [==============================] - 244s 333ms/step - loss: 0.1465 - accuracy: 0.9521 - val_loss: 0.6306 - val_accuracy: 0.8269\n","\n","Epoch 00005: val_accuracy did not improve from 0.83912\n","Epoch 6/20\n","731/731 [==============================] - 244s 333ms/step - loss: 0.1075 - accuracy: 0.9644 - val_loss: 0.6707 - val_accuracy: 0.8276\n","\n","Epoch 00006: val_accuracy did not improve from 0.83912\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WfbB3Dg1Bpq","executionInfo":{"status":"ok","timestamp":1625793253620,"user_tz":-540,"elapsed":335,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"b2dad5fc-d963-4f44-fbe8-272d885ee8eb"},"source":["cls_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_classifier\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tf_bert_model (TFBertModel)  multiple                  92186880  \n","_________________________________________________________________\n","dropout_37 (Dropout)         multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  5383      \n","=================================================================\n","Total params: 92,192,263\n","Trainable params: 92,192,263\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-_I8nv2mTwF9"},"source":["## 모델 Test"]},{"cell_type":"code","metadata":{"id":"T2IayBqpFefT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625793205359,"user_tz":-540,"elapsed":1626,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"297f3407-0a0c-4724-f30a-f4f74b1c54fe"},"source":["\n","\n","input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","train_data_labels = []\n","\n","# bert_tokenizer를 이용하여 encoding진행\n","for test_sent in test[\"clear_title\"]: \n","    try:\n","\n","        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(test_sent)\n","        pass\n","\n","\n","test_news_input_ids = np.array(input_ids, dtype=int)\n","test_news_attention_masks = np.array(attention_masks, dtype=int)\n","test_news_type_ids = np.array(token_type_ids, dtype=int)\n","\n","test_news_inputs = (test_news_input_ids, test_news_attention_masks, test_news_type_ids)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-pChpMn67Att","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"error","timestamp":1625793614985,"user_tz":-540,"elapsed":1881,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"498d4f80-5b7e-4e05-b91a-0c7ac5a289f3"},"source":["\n","cls_model_1 = TFBertClassifier(model_name=model_name,\n","                                                dir_path='bert_ckpt', # ???\n","                                                num_class=NUM_CLASS) # num_class 바꿔야함\n","cls_model_1.load_weights(os.path.join(DATA_OUT_PATH,'best_modeling.h5')) # 오류시 '/weight.h5'\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-67db9a3a29d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                 \u001b[0mdir_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert_ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                 num_class=NUM_CLASS) # num_class 바꿔야함\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_OUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'best_modeling.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 오류시 '/weight.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_news_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2315\u001b[0;31m           \u001b[0;34m'Unable to load weights saved in HDF5 format into a subclassed '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2316\u001b[0m           \u001b[0;34m'Model which has not created its variables yet. Call the Model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m           'first, then load the weights.')\n","\u001b[0;31mValueError\u001b[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."]}]},{"cell_type":"code","metadata":{"id":"xL7BSIBh1oU_"},"source":["\n","predictions = cls_model_1.predict(test_news_inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"0U0ulwNf6-5g","executionInfo":{"status":"ok","timestamp":1625761978364,"user_tz":-540,"elapsed":259,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"ef3f61c5-84ef-43f2-8892-0aff73bf3dae"},"source":["submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45654</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45655</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45656</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45657</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45658</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9126</th>\n","      <td>54780</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9127</th>\n","      <td>54781</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9128</th>\n","      <td>54782</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9129</th>\n","      <td>54783</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9130</th>\n","      <td>54784</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9131 rows × 2 columns</p>\n","</div>"],"text/plain":["      index  topic_idx\n","0     45654          0\n","1     45655          0\n","2     45656          0\n","3     45657          0\n","4     45658          0\n","...     ...        ...\n","9126  54780          0\n","9127  54781          0\n","9128  54782          0\n","9129  54783          0\n","9130  54784          0\n","\n","[9131 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhpiygYK--x3","executionInfo":{"status":"ok","timestamp":1625761980121,"user_tz":-540,"elapsed":252,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"89f5fe20-b693-48b6-d6ec-2adb8478a55e"},"source":["predictions"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2.4011965 ,  0.26372206,  2.8268423 , ..., -3.2180736 ,\n","        -2.4703853 , -2.355632  ],\n","       [-1.1785142 , -2.1982436 ,  0.35500383, ..., -1.476581  ,\n","        -0.9007676 , -0.9627352 ],\n","       [ 0.02171529, -0.05375991,  4.1906133 , ..., -2.3175209 ,\n","        -2.7942715 ,  1.1940738 ],\n","       ...,\n","       [-1.386269  , -1.9737654 ,  4.5388923 , ..., -2.2791831 ,\n","        -2.6202571 , -0.9814434 ],\n","       [ 0.5587819 , -1.8787007 ,  3.6454542 , ..., -3.1510034 ,\n","        -1.9314485 , -0.02879969],\n","       [ 0.4901229 , -0.0325914 ,  3.011536  , ..., -2.3166714 ,\n","        -2.1894653 ,  3.8668249 ]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"sHnjm1OQ24Rn","executionInfo":{"status":"ok","timestamp":1625761983164,"user_tz":-540,"elapsed":244,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"b218fda4-afec-46e4-fa34-1f3e5c18e9b2"},"source":["pred = np.argmax(predictions, axis = 1)\n","submission.topic_idx = pred\n","submission.sample(3)\n","\n","#submission.to_csv(path, index = False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6885</th>\n","      <td>52539</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7356</th>\n","      <td>53010</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>656</th>\n","      <td>46310</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      index  topic_idx\n","6885  52539          4\n","7356  53010          1\n","656   46310          0"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Dkz_FkYq7NJQ","executionInfo":{"status":"ok","timestamp":1625761990628,"user_tz":-540,"elapsed":239,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"44f8fb8c-c027-4e5a-f964-0f2d8263bc60"},"source":["submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45654</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45655</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45656</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45657</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45658</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9126</th>\n","      <td>54780</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>9127</th>\n","      <td>54781</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9128</th>\n","      <td>54782</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9129</th>\n","      <td>54783</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9130</th>\n","      <td>54784</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9131 rows × 2 columns</p>\n","</div>"],"text/plain":["      index  topic_idx\n","0     45654          2\n","1     45655          3\n","2     45656          2\n","3     45657          0\n","4     45658          3\n","...     ...        ...\n","9126  54780          3\n","9127  54781          2\n","9128  54782          2\n","9129  54783          2\n","9130  54784          6\n","\n","[9131 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"mJkO76lD8eGX"},"source":["submission.to_csv('bert_baseline.csv',index = False)\n","# submission.to_csv('bert_baseline_1.csv',index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aReV5iKuFKLP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625620253362,"user_tz":-540,"elapsed":550,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"67a1c7df-c83d-453a-9383-db7c772cc1b6"},"source":["print(history.history)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'loss': [0.7074391841888428, 0.4402851462364197, 0.3594503104686737, 0.29631200432777405, 0.24131686985492706, 0.19897915422916412, 0.1633981466293335], 'accuracy': [0.7605071067810059, 0.8519289493560791, 0.8769816160202026, 0.8973797559738159, 0.9168195128440857, 0.9296607375144958, 0.9425840973854065], 'val_loss': [0.6750518679618835, 0.618735134601593, 0.6169738173484802, 0.6421561241149902, 0.6430529356002808, 0.7034903168678284, 0.7511146664619446], 'val_accuracy': [0.75599604845047, 0.7812944650650024, 0.7889606952667236, 0.7833753228187561, 0.8006790280342102, 0.793012797832489, 0.7873179316520691]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"Eek52q0o-u2i","executionInfo":{"status":"ok","timestamp":1625762005737,"user_tz":-540,"elapsed":290,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"9b76f160-3f0b-468d-b52e-9702dec6b73e"},"source":["\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(loss) + 1)\n","\n","plt.plot(epochs, loss, 'ro', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"mzi6NVrT_tS9","executionInfo":{"status":"ok","timestamp":1625762011802,"user_tz":-540,"elapsed":311,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"979fa095-eb3c-4b7b-ef6c-aab65f4757b0"},"source":["plt.clf()   # 초기화\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UD5946A986ct","executionInfo":{"status":"ok","timestamp":1625762061153,"user_tz":-540,"elapsed":2602,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"3a4499fe-14d6-4048-a4c8-8844ed333dde"},"source":["!pip install dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing ./dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z37_qxxj9ByG","executionInfo":{"status":"ok","timestamp":1625762159764,"user_tz":-540,"elapsed":4519,"user":{"displayName":"james kings","photoUrl":"","userId":"16807751152205018918"}},"outputId":"c819c40f-da21-479a-83e0-cce66cb9a2b0"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","'/content/bert_baseline.csv', # 파일경로\n","'d48ecb3e8cd09e96865d4488c4784b41b44c3f97deba49050f1d400cc324de4a',  # 개인토큰\n","'235747', # 대회 id\n","'Healthy Guys',  # 팀이름\n","'kobert') # 노트"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'isSubmitted': True, 'detail': 'Success'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4-90Wzqw8Jjr"},"source":[""],"execution_count":null,"outputs":[]}]}