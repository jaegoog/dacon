{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"koelectra.ipynb","provenance":[],"mount_file_id":"1wTO0N65aVfxS4_tBYGR1RlyQxKQsP4Bh","authorship_tag":"ABX9TyM40YXhjUP9czG9t1H9IyfS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsHczsI36oOK","executionInfo":{"status":"ok","timestamp":1626784572816,"user_tz":-540,"elapsed":268,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"20485607-29ed-4530-b4b6-8971d301ae74"},"source":["!git checkout tags/v3.5.1"],"execution_count":76,"outputs":[{"output_type":"stream","text":["error: pathspec 'tags/v3.5.1' did not match any file(s) known to git.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AlWjnThYcH4z","executionInfo":{"status":"ok","timestamp":1626781689153,"user_tz":-540,"elapsed":3044,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"34496c78-17af-4113-f7aa-11034406847f"},"source":["pip install transformers"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9JgpJqYqwev","executionInfo":{"status":"ok","timestamp":1626780431691,"user_tz":-540,"elapsed":2921,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"970a99d1-9f45-43f8-81e0-22e2b4678608"},"source":["! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 91, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (85/85), done.\u001b[K\n","remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n","Unpacking objects: 100% (91/91), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGbdYjjLqzhZ","executionInfo":{"status":"ok","timestamp":1626780431694,"user_tz":-540,"elapsed":22,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"0cfc4f8e-8b74-4b55-b28e-63416a61836b"},"source":[" cd Mecab-ko-for-Google-Colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/Mecab-ko-for-Google-Colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skrR_k65qz7f","executionInfo":{"status":"ok","timestamp":1626780651812,"user_tz":-540,"elapsed":220133,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"4e84819c-2b31-47fb-a276-2bda85adbca7"},"source":["! bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Installing konlpy.....\n","Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 46.2 MB/s \n","\u001b[?25hCollecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n","Done\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2021-07-20 11:27:17--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22c3:9b0a, ...\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=jIZrM22G12JppMRc1xya%2BTPXbVg%3D&Expires=1626782086&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n","--2021-07-20 11:27:17--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=jIZrM22G12JppMRc1xya%2BTPXbVg%3D&Expires=1626782086&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.136.129\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.136.129|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.67MB/s    in 0.4s    \n","\n","2021-07-20 11:27:18 (3.67 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2021-07-20 11:28:34--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22c3:9b0a, ...\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=77%2F9fVKjb%2BsdeDOuM%2FP8Zvn5Wyw%3D&Expires=1626782202&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n","--2021-07-20 11:28:34--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=77%2F9fVKjb%2BsdeDOuM%2FP8Zvn5Wyw%3D&Expires=1626782202&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.98.147\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.98.147|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  32.7MB/s    in 1.5s    \n","\n","2021-07-20 11:28:36 (32.7 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","apt-get update\n","apt-get upgrade\n","apt install curl\n","apt install git\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n","Done\n","Successfully Installed\n","Now you can use Mecab\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n","NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n","블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"id6pAv2qqyyw","executionInfo":{"status":"ok","timestamp":1626780654735,"user_tz":-540,"elapsed":2928,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"b240e5f6-f1d6-4291-8489-b82896dcbcb8"},"source":["pip install tensorflow-addons"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n","\u001b[?25l\r\u001b[K     |▌                               | 10 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 679 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.13.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1l4d8ZW8m9rP","executionInfo":{"status":"ok","timestamp":1626794645222,"user_tz":-540,"elapsed":250,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import json\n","import matplotlib.pyplot as plt\n","\n","import seaborn as sns\n","\n","from tqdm import tqdm\n","\n","\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","\n","\n","from transformers import ElectraForSequenceClassification, TFElectraModel, ElectraTokenizer,  ElectraConfig, TFElectraForSequenceClassification\n","\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.sequence import pad_sequences #tensorflow 전처리 모듈1\n","from tensorflow.keras.preprocessing.text import Tokenizer #tensorflow 전처리 모듈2\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# 그래프를 출력창에서 바로 볼 수 있게함\n","%matplotlib inline \n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0rMv_5lm7_Y","executionInfo":{"status":"ok","timestamp":1626794072082,"user_tz":-540,"elapsed":277,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["#################\n","STOPWORDSPATH =\"/content/drive/MyDrive/Colab Notebooks/stopwords.txt\"\n","#################\n","## Import DATA, submission file\n","train = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/train_data.csv\", error_bad_lines=False  )\n","test = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/test_data.csv\",error_bad_lines=False)\n","submission = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/sample_submission.csv\",error_bad_lines=False)\n","topic_dict = pd.read_csv(\"/content/drive/MyDrive/DACON/topic_classification/topic_dict.csv\",error_bad_lines=False)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"lEAvrszbrF1d","executionInfo":{"status":"ok","timestamp":1626794083227,"user_tz":-540,"elapsed":10749,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"5b402ef5-819f-46da-d91b-9570b6c7add1"},"source":["\n","\n","## preprocessing\n","punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n","punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n","\n","def clean_punc(text, punct, mapping):\n","    for p in mapping:\n","        text = text.replace(p, mapping[p])\n","    \n","    for p in punct:\n","        text = text.replace(p, f' {p} ')\n","    \n","    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n","    for s in specials:\n","        text = text.replace(s, specials[s])\n","    \n","    return text.strip()\n","\n","cleaned_train_corpus = []\n","cleaned_test_corpus = []\n","\n","for sent in train['title']:\n","    cleaned_train_corpus.append(clean_punc(sent, punct, punct_mapping))\n","    \n","for sent in test['title']:\n","    cleaned_test_corpus.append(clean_punc(sent, punct, punct_mapping))\n","    \n","\"\"\"\n","\n","1차 전처리 후 반환된 List\n","cleaned_train_corpus \n","cleaned_test_corpus \n","\n","\"\"\"\n","\n","\n","def clean_text(texts):\n","    corpus = []\n","    for i in range(0, len(texts)):\n","        texts[i] = texts[i].replace(\"外人\",\"외국인\")\n","        texts[i] = texts[i].replace(\"日\",\"일본\")\n","        texts[i] = texts[i].replace(\"美\",\"미국\")\n","        texts[i] = texts[i].replace(\"北\",\"북한\")\n","        texts[i] = texts[i].replace(\"英\",\"영국\")\n","        texts[i] = texts[i].replace(\"中\",\"중국\")\n","        texts[i] = texts[i].replace(\"與\",\"여당\")\n","        texts[i] = texts[i].replace(\"靑\",\"청와대\")\n","        texts[i] = texts[i].replace(\"野\",\"야당\")\n","        texts[i] = texts[i].replace(\"伊\",\"이탈리아\")\n","        texts[i] = texts[i].replace(\"韓\",\"한국\")\n","        texts[i] = texts[i].replace(\"南\",\"한국\")\n","        texts[i] = texts[i].replace(\"獨\",\"독일\")\n","        texts[i] = texts[i].replace(\"佛\",\"프랑스\")\n","        texts[i] = texts[i].replace(\"檢\",\"검찰\")\n","        texts[i] = texts[i].replace(\"銀\",\"은행\")\n","        texts[i] = texts[i].replace(\"亞\",\"아시아\")\n","        texts[i] = texts[i].replace(\"人\",\"사람\")\n","        texts[i] = texts[i].replace(\"孫\",\"손혜원\")\n","        texts[i] = texts[i].replace(\"企\",\"기업\")\n","        texts[i] = texts[i].replace(\"前\",\"이전\")\n","        texts[i] = texts[i].replace(\"反\",\"반대\")\n","        texts[i] = texts[i].replace(\"安\",\"안철수\")\n","        texts[i] = texts[i].replace(\"展\",\"전시회\")\n","        texts[i] = texts[i].replace(\"故\",\"사망\")\n","        texts[i] = texts[i].replace(\"文\",\"문재인\")\n","        texts[i] = texts[i].replace(\"新\",\"새로운\")\n","        texts[i] = texts[i].replace(\"曺\",\"조국\")\n","        texts[i] = texts[i].replace(\"朴\",\"박정치인\")\n","        texts[i] = texts[i].replace(\"株\",\"주식\")\n","        texts[i] = texts[i].replace(\"男\",\"남자\")\n","        texts[i] = texts[i].replace(\"硏\",\"연구\")\n","        texts[i] = texts[i].replace(\"車\",\"자동차\")\n","        texts[i] = texts[i].replace(\"軍\",\"군대\")\n","        texts[i] = texts[i].replace(\"重\",\"중공업\")\n","        texts[i] = texts[i].replace(\"R&D\",\"연구개발\")\n","        texts[i] = texts[i].replace(\"문정부\",\"문재인정부\")\n","        \n","\n","\n","        \n","        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(texts[i])) #remove punctuation\n","        review = re.sub(r'\\d+','', str(review))# remove number\n","        review = review.lower() #lower case\n","        review = re.sub(r'\\s+', ' ', review) #remove extra space\n","        review = re.sub(r'<[^>]+>','',review) #remove Html tags\n","        review = re.sub(r'\\s+', ' ', review) #remove spaces\n","        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n","        review = re.sub(r'\\s+$', '', review) #remove space from the end\n","        review = re.sub(\"[一-龥]\",'', review)\n","        corpus.append(review)\n","    return corpus\n","\n","basic_preprocessed_train_corpus = clean_text(cleaned_train_corpus)\n","basic_preprocessed_test_corpus = clean_text(cleaned_test_corpus)\n","\n","\n","\"\"\"\n","\n","2차 전처리 후 반환된 List\n","basic_preprocessed_train_corpus = clean_text(cleaned_train_corpus)\n","basic_preprocessed_test_corpus = clean_text(cleaned_test_corpus)\n","\n","\n","\"\"\"\n","\n","stopwords = []\n","with open(STOPWORDSPATH) as f:\n","    for line in f:\n","        stopwords.append(line.strip())\n","\n","removed_stopword_train_corpus = []\n","removed_stopword_test_corpus = []\n","\n","for tagged in basic_preprocessed_train_corpus:\n","    tagged=mecab.pos(tagged)\n","    \n","    temp = []\n","    for tag in tagged:\n","        #일반명사, 고유명사, 동사, 형용사, 긍정지정사, 부정 지정사, 관형사, 일반부사, 체언접두사, 외국어, 한자\n","        if tag[0] in stopwords or tag[1] not in [\"NNG\", \"NNP\", \"VV\", \"VA\", \"VCP\", \"VCN\", \"MM\", \"MAG\", \"XPN\", \"SL\", \"SH\"]:\n","            continue\n","        temp.append(tag[0])\n","\n","    removed_stopword_train_corpus.append(' '.join(temp))\n","    \n","for tagged in basic_preprocessed_test_corpus:\n","    tagged=mecab.pos(tagged)\n","    \n","    temp = []\n","    for tag in tagged:\n","        if tag[0] in stopwords or tag[1] not in [\"NNG\", \"NNP\", \"VV\", \"VA\", \"VCP\", \"VCN\", \"MM\", \"MAG\", \"XPN\", \"SL\", \"SH\"]:\n","            continue\n","        temp.append(tag[0])\n","\n","    removed_stopword_test_corpus.append(' '.join(temp))\n","\n","\n","\n","\"\"\"\n","\n","3차 전처리후 반환된 List\n","removed_stopword_train_corpus = []\n","removed_stopword_test_corpus = []\n","\n","\"\"\"\n","\n","\"\"\"   \n","##########################################\n","###############최종 전처리###################\n","##########################################\n","\"\"\"\n","train_text = removed_stopword_train_corpus\n","test_text = removed_stopword_test_corpus\n","train_label = np.asarray(train.topic_idx)\n","\"\"\"\n","##########################################\n","##########################################\n","\"\"\""],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n##########################################\\n##########################################\\n'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"YEMC__GQrJZ5","executionInfo":{"status":"ok","timestamp":1626794083228,"user_tz":-540,"elapsed":11,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["train['clear_title'] = train_text\n","test['clear_title'] = test_text"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"gudjj5LYeOVR","executionInfo":{"status":"ok","timestamp":1626794083229,"user_tz":-540,"elapsed":11,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"9c734ab6-e68a-4279-f318-974a175c02df"},"source":["train"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>title</th>\n","      <th>topic_idx</th>\n","      <th>clear_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n","      <td>4</td>\n","      <td>인천 핀란드 항공기 결항 휴가철 여행객 분통</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n","      <td>4</td>\n","      <td>실리콘밸리 넘어서 구글 조원 미국 전역 거점</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n","      <td>4</td>\n","      <td>이란 외무 긴장 완화 해결책 미국 경제 전쟁 멈추</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n","      <td>4</td>\n","      <td>nyt 클린턴 측근 한국 기업 특수 관계 조명 공과 종합</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n","      <td>4</td>\n","      <td>시진핑 트럼프 중미 무역 협상 조속 타결 희망</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>45649</th>\n","      <td>45649</td>\n","      <td>KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략</td>\n","      <td>1</td>\n","      <td>kb 금융 미국 ib 스티펠 제휴 선진국 시장 공략</td>\n","    </tr>\n","    <tr>\n","      <th>45650</th>\n","      <td>45650</td>\n","      <td>1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토</td>\n","      <td>2</td>\n","      <td>보 서울시 교육청 신종 코로나 확산 개학 연기 휴업 검토</td>\n","    </tr>\n","    <tr>\n","      <th>45651</th>\n","      <td>45651</td>\n","      <td>게시판 키움증권 2020 키움 영웅전 실전투자대회</td>\n","      <td>1</td>\n","      <td>게시판 키움증권 영웅전 실전 투자 대회</td>\n","    </tr>\n","    <tr>\n","      <th>45652</th>\n","      <td>45652</td>\n","      <td>답변하는 배기동 국립중앙박물관장</td>\n","      <td>2</td>\n","      <td>답변 배기동 국립 중앙 박물 관장</td>\n","    </tr>\n","    <tr>\n","      <th>45653</th>\n","      <td>45653</td>\n","      <td>2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후</td>\n","      <td>2</td>\n","      <td>한국 인터넷 기자상 시상식 내달 최 특별상 김성후</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>45654 rows × 4 columns</p>\n","</div>"],"text/plain":["       index  ...                      clear_title\n","0          0  ...         인천 핀란드 항공기 결항 휴가철 여행객 분통\n","1          1  ...         실리콘밸리 넘어서 구글 조원 미국 전역 거점\n","2          2  ...      이란 외무 긴장 완화 해결책 미국 경제 전쟁 멈추\n","3          3  ...  nyt 클린턴 측근 한국 기업 특수 관계 조명 공과 종합\n","4          4  ...        시진핑 트럼프 중미 무역 협상 조속 타결 희망\n","...      ...  ...                              ...\n","45649  45649  ...     kb 금융 미국 ib 스티펠 제휴 선진국 시장 공략\n","45650  45650  ...  보 서울시 교육청 신종 코로나 확산 개학 연기 휴업 검토\n","45651  45651  ...            게시판 키움증권 영웅전 실전 투자 대회\n","45652  45652  ...               답변 배기동 국립 중앙 박물 관장\n","45653  45653  ...      한국 인터넷 기자상 시상식 내달 최 특별상 김성후\n","\n","[45654 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkpwXPYxg6Zh","executionInfo":{"status":"ok","timestamp":1626794758018,"user_tz":-540,"elapsed":2075,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"9abb2677-495e-401d-cb70-215e459cbdb0"},"source":["model = ElectraForSequenceClassification.from_pretrained(model_name,num_labels=2) \n","import torch\n","model.cuda()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"5NtufzrdfIWs","executionInfo":{"status":"ok","timestamp":1626794137069,"user_tz":-540,"elapsed":1982,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQlHXO1ee3r5","executionInfo":{"status":"ok","timestamp":1626794138886,"user_tz":-540,"elapsed":320,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"ab96daca-1d0e-4bad-a993-25d56872d299"},"source":["tokenizer.tokenize(\"[CLS] 한국어 ELECTRA를 공유합니다. [SEP]\")"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]', '한국어', 'EL', '##EC', '##TRA', '##를', '공유', '##합니다', '.', '[SEP]']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Dg1wcmaft8j","executionInfo":{"status":"ok","timestamp":1626794139293,"user_tz":-540,"elapsed":3,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"1e65f3a9-4d56-4ac2-a223-87cb332fd7c3"},"source":["tokenizer.convert_tokens_to_ids(['[CLS]', '한국어', 'EL', '##EC', '##TRA', '##를', '공유', '##합니다', '.', '[SEP]'])\n"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 11229, 29173, 13352, 25541, 4110, 7824, 17788, 18, 3]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"svPlwqjQppkL","executionInfo":{"status":"ok","timestamp":1626794714973,"user_tz":-540,"elapsed":256,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["model_name = \"monologg/koelectra-base-v3-discriminator\"\n","SEED_NUM = 977\n","tf.random.set_seed(SEED_NUM)\n","np.random.seed(SEED_NUM)\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 5\n","VALID_SPLIT = 0.2\n","MAX_LEN = 25\n","NUM_CLASS = 7\n","K_SPLIT = 3\n","# 이상치 데이터로인해 평균이 급격히 올라갈수 있기에 EDA분석을 통해 적절히 정해야함 평균값이던 중간값이던 3사분위 값이던\n","# EDA를 통해 이상치 데이터가 없으면 최대값이용"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDE0c4dMfvpf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626794963623,"user_tz":-540,"elapsed":8110,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"3b173e3c-de17-4b17-c82e-48cdcc59b3c9"},"source":["indices=tokenizer.batch_encode_plus(train[\"clear_title\"],\n","                                    max_length=32,\n","                                    add_special_tokens=True, \n","                                    return_attention_mask=True,\n","                                    pad_to_max_length=True,\n","                                    truncation=True)\n","input_ids=indices[\"input_ids\"]\n","attention_masks=indices[\"attention_mask\"]\n","\n","\n","\n","def koelectra_tokenizer(sent, MAX_LEN):\n","\n","    encoded_dict = tokenizer.encode_plus(\n","        \n","        text = sent,\n","        add_special_tokens = True, # True : 토큰 시작점에 [CLS] 토큰과 토큰의 마지막에 [SEP]토큰을 붙임\n","        max_length = MAX_LEN, # MAX_LEN 최대 길이에 따라 문장의 길이를 맞추는 작업을 진행 ; MAX_LEN보다 길면 truncate\n","        pad_to_max_length = True, # True : MAX_LEN의 길이에 미치지 못하는 문장에 padding을 적용 **padding : 길이를 일괄적으로 맞춰주는 것\n","                                                     # 각 데이터의 길이가 다를경우 모델에 적용할 수 없음 그렇기에 padding진행\n","        return_token_type_ids=None,\n","        return_attention_mask = True, # True : BERT에 필요한 입력값 중 attention_mask를 생성\n","        truncation = True \n","        # encoded_plus 과정 중 token_type으로 문장이 1개면 0, 문장이 2개면 0과 1로 구분\n","    )\n","\n","\n","    input_id = encoded_dict['input_ids'] # BERT 입력값 중 하나인 input_ids\n","    attention_mask = encoded_dict['attention_mask'] # attention_mask ; 단순히 padding과 non-padding을 구분\n","\n","\n","\n","    return input_id, attention_mask # 각각의 BERT 입력값들을 encoded_dict를 한 결과를 return"],"execution_count":34,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfAU1DYNiqR3","executionInfo":{"status":"ok","timestamp":1626795734108,"user_tz":-540,"elapsed":258,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"5ed8743f-beee-4f16-b27b-6407e12fb827"},"source":["train_input_ids = np.array(input_ids, dtype=np.int64)\n","train_attention_mask = np.array(attention_mask, dtype=np.int64)\n","\n","train_all_inputs = (train_input_ids, train_attention_mask)\n","train_data_labels = []\n","for i in train['topic_idx']:\n","    train_data_labels.append(i)\n","train_data_labels = np.asarray(train_data_labels, dtype=np.int64) \n","train_data_labels"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 4, 4, ..., 1, 2, 2])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HjpOmhAmRbj","executionInfo":{"status":"ok","timestamp":1626796008096,"user_tz":-540,"elapsed":262,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"1654a374-f89b-46b6-f52f-785c261035a9"},"source":["attention_mask"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PwkiJOilb7-","executionInfo":{"status":"ok","timestamp":1626795824990,"user_tz":-540,"elapsed":265,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"46e32428-80ef-4d09-9975-a067d7e76c16"},"source":["train_all_inputs"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[    2,  6787, 15093, ...,     0,     0,     0],\n","        [    2, 24019, 11882, ...,     0,     0,     0],\n","        [    2,  6589, 12881, ...,     0,     0,     0],\n","        ...,\n","        [    2, 12673, 24732, ...,     0,     0,     0],\n","        [    2,  8610, 15287, ...,     0,     0,     0],\n","        [    2,  6244,  6811, ...,     0,     0,     0]]),\n"," array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0]))"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"wNQK_-0OnLDB","executionInfo":{"status":"error","timestamp":1626794458718,"user_tz":-540,"elapsed":1727,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"b2abe34a-18a7-4c76-add1-44c37e93a5f0"},"source":["class TFElectraClassification(tf.keras.Model): # pre_trained된 bert model을 불러와 그 위에 완전연결층 1층을 쌓은 구조\n","                                                              # class로 모델을 구현하려면 tf.keras.Model을 상속받아야 함\n","    # TFBertClassifier생성할 때마다 __init__실행                                                          \n","    def __init__(self, model_name, dir_path, num_class): # model_name : 인자로 받아 활용할 모델 이름, dir_path : 모델이 저장된 위치\n","                                                                                            # num_class : 원하는 정답의 개수(감성분석인 경우 2; 긍정, 부정)\n","        # super함수를 통해 부모 클래스(tf.keras.Model)에 있는 __init__함수 호출   \n","        # tf.keras.Model 클래스를 상속받는 경우 super함수를 통해 부모 클래스에 __init__ 함수의 인자에 모델이름을 전달하면\n","        # tf.keras.Model을 상속받은 모든 자식은 해당 모델의 이름으로 공통적으로 사용\n","        super(TFElectraClassification, self).__init__()\n","\n","         \n","        \n","        self.model = TFElectraForSequenceClassification.from_pretrained(model_name, num_labels=NUM_CLASS)          \n","\n","        self.dropout = tf.keras.layers.Dropout(self.model.config.hidden_dropout_prob) # 과적합을 방지하기 위한 layer\n","        # self.classifier을 통해 topic_idx를 전부 분류\n","        self.classifier = tf.keras.layers.Dense(num_class,\n","                                                                    kernel_initializer=tf.keras.initializers.TruncatedNormal(self.model.config.initializer_range), \n","                                                                    name=\"classifier\")  # 완전연결층 1층\n","\n","\n","    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False): \n","        #__init__에서 선언한 내용을 실제 입력을 받고 실행하는 call 메서드임\n","        # call함수를 호출하면 입력한 inputs을 통해 마지막에 예측값을 출력\n","        # 영화 리뷰 text를 inputs을 통해 받음\n","        \n","\n","        # output 값 : last_hidden_state , hidden_states, attentions\n","        # sequence_output : sequence 길이의 출력을 모두 입력으로 받음; 이 벡터의 차원 ' 임베딩 크기 * 최대문장길이'\n","        outputs = self.model(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids) # bert를 통해 outputs로 결과값을 추출\n","        pooled_output = outputs[1] # pooled_output\n","        pooled_output = self.dropout(pooled_output, training=training)\n","        logits = self.classifier(pooled_output) # self.classifier를 통해 완전연결층을 활용하여 최종적으로 self.num_labels 개수에 맞는 예측값을 출력\n","\n","        return logits\n","\n","cls_model = TFElectraClassification(model_name=model_name,\n","                                                dir_path='bert_ckpt', # ???\n","                                                num_class=NUM_CLASS) # num_class 바꿔야함\n","\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing TFElectraForSequenceClassification: ['discriminator_predictions']\n","- This IS expected if you are initializing TFElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-6ee10efce1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m cls_model = TFElectraClassification(model_name=model_name,\n\u001b[1;32m     38\u001b[0m                                                 \u001b[0mdir_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert_ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                                 num_class=NUM_CLASS) # num_class 바꿔야함\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-6ee10efce1f3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, dir_path, num_class)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFElectraForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dropout_prob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 과적합을 방지하기 위한 layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# self.classifier을 통해 topic_idx를 전부 분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'TFElectraForSequenceClassification' object has no attribute 'cuda'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X86VW8XUqmuF","executionInfo":{"status":"ok","timestamp":1626796200092,"user_tz":-540,"elapsed":10972,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"0b24e193-2fe6-4d2c-9189-2176ba4552ee"},"source":["\n","input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","train_data_labels = []\n","\n","# bert_tokenizer를 이용하여 encoding진행\n","for train_sent, train_label in tqdm(zip(train[\"clear_title\"], train[\"topic_idx\"])): \n","    try:\n","\n","        input_id, attention_mask = koelectra_tokenizer(train_sent, MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        train_data_labels.append(train_label)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(train_sent)\n","        pass\n","\n","\n","train_news_input_ids = np.array(input_ids, dtype=np.int64)\n","train_news_attention_masks = np.array(attention_masks, dtype=np.int64)\n","\n","# 최종 출력값은 numpy로 변환한 후 tuple 형태로 묶어서 저장\n","train_news_inputs = (train_news_input_ids, train_news_attention_masks)\n","\n","train_data_labels = np.asarray(train_data_labels, dtype=np.int64) # 정답 tokenizing 리스트\n"],"execution_count":54,"outputs":[{"output_type":"stream","text":["0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","45654it [00:10, 4309.79it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TLCkO279luXH","executionInfo":{"status":"ok","timestamp":1626795935038,"user_tz":-540,"elapsed":294,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"f79850d1-bf94-416e-de81-4ec0709cacbe"},"source":["train_news_attention_masks"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       ...,\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-0rk2tblws-","executionInfo":{"status":"ok","timestamp":1626795963928,"user_tz":-540,"elapsed":254,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"85bcb920-c6c4-401b-9989-8b0037a75b5a"},"source":["train_attention_mask\n"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVD627OAvRcL","executionInfo":{"status":"ok","timestamp":1626794174804,"user_tz":-540,"elapsed":270,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"d4e3d17c-3819-4c83-df32-455257443e5d"},"source":["# bert_tokenizer를 통해 실제결과가 나오는지 테스트\n","print_num = 30\n","INPUT_id = train_news_input_ids[print_num]\n","ATTENTION_mask = train_news_attention_masks[print_num]\n","\n","berttokenizer_text = tokenizer.tokenize(train['clear_title'][print_num])\n","mecabtokenizer_text = mecab.morphs(train['clear_title'][print_num])\n","mecabtokenizer_text_1 = mecab.nouns(train['clear_title'][print_num])\n","\n","print(INPUT_id)\n","print(ATTENTION_mask)\n","\n","print(\"#\"*50)\n","print(train['clear_title'][print_num])\n","print(mecabtokenizer_text)\n","print(mecabtokenizer_text_1)\n","print(\"#\"*50)\n","print(berttokenizer_text)\n","print(tokenizer.decode(INPUT_id))\n","print(\"#\"*50)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[    2  2942  7129 28472  4051  6498 10044  6673  3472  4883  6325  7750\n","  6624  6696     3     0     0     0     0     0     0     0     0     0\n","     0]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n","##################################################\n","셰이크 afc 회장 평양 방문 최휘 국가 체육 지도 위원장\n","['셰이크', 'afc', '회장', '평양', '방문', '최휘', '국가', '체육', '지도', '위원장']\n","['셰이크', '회장', '평양', '방문', '최휘', '국가', '체육', '지도', '위원장']\n","##################################################\n","['셰', '##이크', 'af', '##c', '회장', '평양', '방문', '최', '##휘', '국가', '체육', '지도', '위원장']\n","[CLS] 셰이크 afc 회장 평양 방문 최휘 국가 체육 지도 위원장 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","##################################################\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qaPJYLh4vU8F","executionInfo":{"status":"ok","timestamp":1626794182514,"user_tz":-540,"elapsed":259,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["\n","optimizer = tfa.optimizers.RectifiedAdam(learning_rate=5e-3, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","cls_model.compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4GixJ0OsdQjm","executionInfo":{"status":"ok","timestamp":1626794183543,"user_tz":-540,"elapsed":3,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"8ad7a696-4ae3-40c9-c981-c1dd437ebfd7"},"source":["# 모델이 어느 시점이 되면 학습평가점수는 높아지는데 검증평가 점수가 낮아지는 overfitting현상이 발생하거나\n","# 학습도중 특정 상태의 모델에서 하이퍼파라미터를 바꿔서 다시 학습을 진행할 수도 있음\n","# => tensowflow.keras.callback 모듈의 EarlyStopping, ModelCheckpoint 클래스를 활용하여 해결\n","\n","\n","# 특정 epoch에서 현재 검증 평가 점수가 이전 검증 평가 점수보다 일정수치 미만으로 낮아지면 학습을 멈추는 역할\n","# 학습 중 overfitting을 방지한다는 것\n","es_callback = EarlyStopping(\n","                                monitor='val_loss', # 'val_accuracy'를 통해 검증 평가 점수로 활용한다는 것\n","                                mode='min',\n","                                min_delta=0.0001, # 활용한 평가 점수에 따라 현재 점수가 이전 점수에 비해 0.0001 보다 낮아지면 overfitting현상이 발생한다고 생각하고 학습을 멈춤\n","                                patience=3,\n","                                baseline=0.4\n","                                 ) # 검증 평가 점수가 이전 최고 점수보다 높아지지 않는 epoch수가 patience에 입력한 횟수를 넘어가면 학습을 멈춤\n","\n","# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n","# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n","\n","\n","\n","DATA_OUT_PATH = '/content/drive/MyDrive/best_model'\n","# 오류시 DATA_OUT_PATH = '/content/gdrive/MyDrive/bert_data_out'\n","\n","checkpoint_path = DATA_OUT_PATH +  '/best_modeling.ckpt'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create path if exists\n","if os.path.exists(checkpoint_dir):\n","    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","# Epoch마다 모델을 저장하게끔 함(학습중 모델을 저장한다는 것)    \n","cp_callback = ModelCheckpoint(\n","    checkpoint_path, \n","    monitor='val_accuracy', # save_best_only를 하는 평가기준\n","    verbose=1, \n","    save_best_only=True, # True : 가장 성능이 좋은 모델만 저장한다는 것\n","    save_weights_only=True # True : 모델 그래프를 전부 저장하는 것이 아닌 모델 가중치만 저장한다는 것\n","    )\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/best_model -- Folder already exists \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":582},"id":"n9TV6Z15vtM5","executionInfo":{"status":"error","timestamp":1626796218372,"user_tz":-540,"elapsed":2591,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}},"outputId":"617ce13e-b9ee-4dc3-8d96-6441155956fb"},"source":["\n","# 학습과 eval 시작\n","history = cls_model.fit(train_news_inputs, train_data_labels, \n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        validation_split = VALID_SPLIT, # 학습데이터에서 일정한 비율로 무작위로 나눔\n","                        callbacks=[es_callback, cp_callback]\n","                        ) # 검증데이터셋이 있을경우 파라미터로 validation_data = 로 데이터셋을 지정한 다음 validation_split파라미터를 지운다."],"execution_count":55,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"error","ename":"StagingError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-7dc30195e182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVALID_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 학습데이터에서 일정한 비율로 무작위로 나눔\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                         ) # 검증데이터셋이 있을경우 파라미터로 validation_data = 로 데이터셋을 지정한 다음 validation_split파라미터를 지운다.\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3440\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3441\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3363\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-15-b7d215bdb959>:31 call  *\n        pooled_output = outputs[1] # pooled_output\n    /usr/local/lib/python3.7/dist-packages/transformers/file_utils.py:1808 __getitem__\n        return self.to_tuple()[k]\n\n    IndexError: tuple index out of range\n"]}]},{"cell_type":"code","metadata":{"id":"3U0zw5XrdUto"},"source":["\n","\n","input_ids = []\n","attention_masks = []\n","train_data_labels = []\n","\n","# bert_tokenizer를 이용하여 encoding진행\n","for test_sent in test[\"clear_title\"]: \n","    try:\n","\n","        input_id, attention_mask, token_type_id = koelectra_tokenizer(test_sent, MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(test_sent)\n","        pass\n","\n","\n","test_news_input_ids = np.array(input_ids, dtype=int)\n","test_news_attention_masks = np.array(attention_masks, dtype=int)\n","\n","test_news_inputs = (test_news_input_ids, test_news_attention_masks)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTHzgdNTdvTU"},"source":["# model.load_weights(checkpoint_filepath)\n","cls_model_1 = TFBertClassifier(model_name=model_name,\n","                                                dir_path='bert_ckpt', # ???\n","                                                num_class=NUM_CLASS) # num_class 바꿔야함\n","cls_model_1.load_weights(os.path.join(DATA_OUT_PATH,'best_modeling.ckpt')) # 오류시 '/weight.h5'\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lx2UwnrXdx4v"},"source":["\n","predictions = cls_model_1.predict(test_news_inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ul-QltQ8d0eD"},"source":["pred = np.argmax(predictions, axis = 1)\n","submission.topic_idx = pred\n","submission.sample(3)\n","\n","#submission.to_csv(path, index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99vFGMWBd2xg"},"source":["submission.to_csv('bert_baseline_1.csv',index = False)\n","# submission.to_csv('bert_baseline_1.csv',index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4Eb8bwEd7SQ"},"source":["!pip install dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtCMJRFqd894"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","'/content/bert_baseline_1.csv', # 파일경로\n","'9172b3a5dd7b1a01347dd23e300a335759dc728bf1454cd00f66ca6aa28bf2d3',  # 개인토큰\n","'235747', # 대회 id\n","'Healthy Guys',  # 팀이름\n","'koelectra_R_Adam_2') # 노트"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmD1EATWGRph","executionInfo":{"status":"ok","timestamp":1626787620447,"user_tz":-540,"elapsed":296,"user":{"displayName":"민재국","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjBOLjrCu_K1IRZgoIsbZkHEub3y3tu99BC2Ml=s64","userId":"06973770692738835288"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers.activations import get_activation\n","from transformers import (\n","  ElectraPreTrainedModel,\n","  ElectraModel,\n","  ElectraConfig,\n","  ElectraTokenizer,\n","  BertConfig,\n","  BertTokenizer\n",")\n","\n","# MODEL_CLASSES = {\n","#     \"koelectra-base\": (ElectraConfig, koElectraForSequenceClassification, ElectraTokenizer),\n","#     \"koelectra-small\": (ElectraConfig, koElectraForSequenceClassification, ElectraTokenizer),\n","#     \"koelectra-base-v2\": (ElectraConfig, koElectraForSequenceClassification, ElectraTokenizer),\n","#     \"koelectra-small-v2\": (ElectraConfig, koElectraForSequenceClassification, ElectraTokenizer),\n","# }\n","\n","\n","# def load_tokenizer(args):\n","#   return MODEL_CLASSES[args.model_type][2].from_pretrained(args.model_name_or_path)\n","\n","\n","class ElectraClassificationHead(nn.Module):\n","  \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","  def __init__(self, config, num_labels):\n","    super().__init__()\n","    self.dense = nn.Linear(config.hidden_size, 4*config.hidden_size)\n","    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","    self.out_proj = nn.Linear(4*config.hidden_size,num_labels)\n","\n","  def forward(self, features, **kwargs):\n","    x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n","    x = self.dropout(x)\n","    x = self.dense(x)\n","    x = get_activation(\"gelu\")(x)  # although BERT uses tanh here, it seems Electra authors used gelu here\n","    x = self.dropout(x)\n","    x = self.out_proj(x)\n","    return x\n","\n","class koElectraForSequenceClassification(ElectraPreTrainedModel):\n","  def __init__(self,\n","               config,\n","               num_labels):\n","    super().__init__(config)\n","    self.num_labels = num_labels\n","    self.electra = ElectraModel(config)\n","    self.classifier = ElectraClassificationHead(config, num_labels)\n","\n","    self.init_weights()\n","  def forward(\n","          self,\n","          input_ids=None,\n","          attention_mask=None,\n","          token_type_ids=None,\n","          position_ids=None,\n","          head_mask=None,\n","          inputs_embeds=None,\n","          labels=None,\n","          output_attentions=None,\n","          output_hidden_states=None,\n","  ):\n","    r\"\"\"\n","    labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n","        Labels for computing the sequence classification/regression loss.\n","        Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n","        If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n","        If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","    \"\"\"\n","    discriminator_hidden_states = self.electra(\n","      input_ids,\n","      attention_mask,\n","      token_type_ids,\n","      position_ids,\n","      head_mask,\n","      inputs_embeds,\n","      output_attentions,\n","      output_hidden_states,\n","    )\n","\n","    sequence_output = discriminator_hidden_states[0]\n","    logits = self.classifier(sequence_output)\n","\n","    outputs = (logits,) + discriminator_hidden_states[1:]  # add hidden states and attention if they are here\n","\n","    if labels is not None:\n","      if self.num_labels == 1:\n","        #  We are doing regression\n","        loss_fct = MSELoss()\n","        loss = loss_fct(logits.view(-1), labels.view(-1))\n","      else:\n","        loss_fct = CrossEntropyLoss()\n","        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","      outputs = (loss,) + outputs\n","\n","    return outputs  # (loss), (logits), (hidden_states), (attentions)\n","\n","def koelectra_input(tokenizer, str, device = None, max_seq_len = 512):\n","  index_of_words = tokenizer.encode(str)\n","  # token_type_ids = [0] * len(index_of_words)\n","  attention_mask = [1] * len(index_of_words)\n","\n","  # Padding Length\n","  padding_length = max_seq_len - len(index_of_words)\n","\n","  # Zero Padding\n","  index_of_words += [0] * padding_length\n","  # token_type_ids += [0] * padding_length\n","  attention_mask += [0] * padding_length\n","\n","  data = {\n","    'input_ids': torch.tensor([index_of_words]).to(device),\n","    'attention_mask': torch.tensor([attention_mask]).to(device),\n","  }\n","  return data"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VRZj0Omv6_i"},"source":["#!/usr/bin/env python`a\n","# coding=utf-8\n","# Copyright 2021 The HuggingFace Inc. team. All rights reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\" Fine-tuning the library models for sequence classification.\"\"\"\n","# You can also adapt this script on your own text classification task. Pointers for this are left as comments.\n","\n","import logging\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from pathlib import Path\n","from typing import Optional\n","\n","import numpy as np\n","from datasets import load_dataset\n","\n","from transformers import (\n","    AutoConfig,\n","    AutoTokenizer,\n","    HfArgumentParser,\n","    PretrainedConfig,\n","    TFAutoModelForSequenceClassification,\n","    TFTrainingArguments,\n","    set_seed,\n",")\n","from transformers.file_utils import CONFIG_NAME, TF2_WEIGHTS_NAME\n","\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # Reduce the amount of console output from TF\n","import tensorflow as tf  # noqa: E402\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","# region Helper classes\n","class SavePretrainedCallback(tf.keras.callbacks.Callback):\n","    # Hugging Face models have a save_pretrained() method that saves both the weights and the necessary\n","    # metadata to allow them to be loaded as a pretrained model in future. This is a simple Keras callback\n","    # that saves the model with this method after each epoch.\n","    def __init__(self, output_dir, **kwargs):\n","        super().__init__()\n","        self.output_dir = output_dir\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.model.save_pretrained(self.output_dir)\n","\n","\n","def convert_dataset_for_tensorflow(\n","    dataset, non_label_column_names, batch_size, dataset_mode=\"variable_batch\", shuffle=True, drop_remainder=True\n","):\n","    \"\"\"Converts a Hugging Face dataset to a Tensorflow Dataset. The dataset_mode controls whether we pad all batches\n","    to the maximum sequence length, or whether we only pad to the maximum length within that batch. The former\n","    is most useful when training on TPU, as a new graph compilation is required for each sequence length.\n","    \"\"\"\n","\n","    def densify_ragged_batch(features, label=None):\n","        features = {\n","            feature: ragged_tensor.to_tensor(shape=batch_shape[feature]) for feature, ragged_tensor in features.items()\n","        }\n","        if label is None:\n","            return features\n","        else:\n","            return features, label\n","\n","    feature_keys = list(set(dataset.features.keys()) - set(non_label_column_names + [\"label\"]))\n","    if dataset_mode == \"variable_batch\":\n","        batch_shape = {key: None for key in feature_keys}\n","        data = {key: tf.ragged.constant(dataset[key]) for key in feature_keys}\n","    elif dataset_mode == \"constant_batch\":\n","        data = {key: tf.ragged.constant(dataset[key]) for key in feature_keys}\n","        batch_shape = {\n","            key: tf.concat(([batch_size], ragged_tensor.bounding_shape()[1:]), axis=0)\n","            for key, ragged_tensor in data.items()\n","        }\n","    else:\n","        raise ValueError(\"Unknown dataset mode!\")\n","\n","    if \"label\" in dataset.features:\n","        labels = tf.convert_to_tensor(np.array(dataset[\"label\"]))\n","        tf_dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n","    else:\n","        tf_dataset = tf.data.Dataset.from_tensor_slices(data)\n","    if shuffle:\n","        tf_dataset = tf_dataset.shuffle(buffer_size=len(dataset))\n","    tf_dataset = tf_dataset.batch(batch_size=batch_size, drop_remainder=drop_remainder).map(densify_ragged_batch)\n","    return tf_dataset\n","\n","\n","# endregion\n","\n","\n","# region Command-line arguments\n","@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","    Using `HfArgumentParser` we can turn this class\n","    into argparse arguments to be able to specify them on\n","    the command line.\n","    \"\"\"\n","\n","    train_file: Optional[str] = field(\n","        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n","    )\n","    validation_file: Optional[str] = field(\n","        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n","    )\n","    test_file: Optional[str] = field(default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"})\n","\n","    max_seq_length: int = field(\n","        default=128,\n","        metadata={\n","            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n","            \"than this will be truncated, sequences shorter will be padded.\"\n","        },\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n","    )\n","    pad_to_max_length: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n","            \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n","            \"Data will always be padded when using TPUs.\"\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_val_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of validation examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","    max_test_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"For debugging purposes or quicker training, truncate the number of test examples to this \"\n","            \"value if set.\"\n","        },\n","    )\n","\n","    def __post_init__(self):\n","        train_extension = self.train_file.split(\".\")[-1].lower() if self.train_file is not None else None\n","        validation_extension = (\n","            self.validation_file.split(\".\")[-1].lower() if self.validation_file is not None else None\n","        )\n","        test_extension = self.test_file.split(\".\")[-1].lower() if self.test_file is not None else None\n","        extensions = {train_extension, validation_extension, test_extension}\n","        extensions.discard(None)\n","        assert len(extensions) != 0, \"Need to supply at least one of --train_file, --validation_file or --test_file!\"\n","        assert len(extensions) == 1, \"All input files should have the same file extension, either csv or json!\"\n","        assert \"csv\" in extensions or \"json\" in extensions, \"Input files should have either .csv or .json extensions!\"\n","        self.input_file_extension = extensions.pop()\n","\n","\n","@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    use_auth_token: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n","            \"with private models).\"\n","        },\n","    )\n","\n","\n","# endregion\n","\n","\n","def main():\n","    # region Argument parsing\n","    # See all possible arguments in src/transformers/training_args.py\n","    # or by passing the --help flag to this script.\n","    # We now keep distinct sets of args, for a cleaner separation of concerns.\n","\n","    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TFTrainingArguments))\n","    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n","        # If we pass only one argument to the script and it's the path to a json file,\n","        # let's parse it to get our arguments.\n","        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n","    else:\n","        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n","    output_dir = Path(training_args.output_dir)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","    # endregion\n","\n","    # region Checkpoints\n","    # Detecting last checkpoint.\n","    checkpoint = None\n","    if len(os.listdir(training_args.output_dir)) > 0 and not training_args.overwrite_output_dir:\n","        if (output_dir / CONFIG_NAME).is_file() and (output_dir / TF2_WEIGHTS_NAME).is_file():\n","            checkpoint = output_dir\n","            logger.info(\n","                f\"Checkpoint detected, resuming training from checkpoint in {training_args.output_dir}. To avoid this\"\n","                \" behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","            )\n","        else:\n","            raise ValueError(\n","                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","                \"Use --overwrite_output_dir to continue regardless.\"\n","            )\n","\n","    # endregion\n","\n","    # region Logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        handlers=[logging.StreamHandler(sys.stdout)],\n","    )\n","    logger.setLevel(logging.INFO)\n","\n","    logger.info(f\"Training/evaluation parameters {training_args}\")\n","    # endregion\n","\n","    # region Loading data\n","    # For CSV/JSON files, this script will use the 'label' field as the label and the 'sentence1' and optionally\n","    # 'sentence2' fields as inputs if they exist. If not, the first two fields not named label are used if at least two\n","    # columns are provided. Note that the term 'sentence' can be slightly misleading, as they often contain more than\n","    # a single grammatical sentence, when the task requires it.\n","    #\n","    # If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this\n","    # single column. You can easily tweak this behavior (see below)\n","    #\n","    # In distributed training, the load_dataset function guarantee that only one local process can concurrently\n","    # download the dataset.\n","    data_files = {\"train\": data_args.train_file, \"validation\": data_args.validation_file, \"test\": data_args.test_file}\n","    data_files = {key: file for key, file in data_files.items() if file is not None}\n","\n","    for key in data_files.keys():\n","        logger.info(f\"Loading a local file for {key}: {data_files[key]}\")\n","\n","    if data_args.input_file_extension == \"csv\":\n","        # Loading a dataset from local csv files\n","        datasets = load_dataset(\"csv\", data_files=data_files, cache_dir=model_args.cache_dir)\n","    else:\n","        # Loading a dataset from local json files\n","        datasets = load_dataset(\"json\", data_files=data_files, cache_dir=model_args.cache_dir)\n","    # See more about loading any type of standard or custom dataset at\n","    # https://huggingface.co/docs/datasets/loading_datasets.html.\n","    # endregion\n","\n","    # region Label preprocessing\n","    # If you've passed us a training set, we try to infer your labels from it\n","    if \"train\" in datasets:\n","        # By default we assume that if your label column looks like a float then you're doing regression,\n","        # and if not then you're doing classification. This is something you may want to change!\n","        is_regression = datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]\n","        if is_regression:\n","            num_labels = 1\n","        else:\n","            # A useful fast method:\n","            # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n","            label_list = datasets[\"train\"].unique(\"label\")\n","            label_list.sort()  # Let's sort it for determinism\n","            num_labels = len(label_list)\n","    # If you haven't passed a training set, we read label info from the saved model (this happens later)\n","    else:\n","        num_labels = None\n","        label_list = None\n","        is_regression = None\n","    # endregion\n","\n","    # region Load model config and tokenizer\n","    if checkpoint is not None:\n","        config_path = training_args.output_dir\n","    elif model_args.config_name:\n","        config_path = model_args.config_name\n","    else:\n","        config_path = model_args.model_name_or_path\n","    if num_labels is not None:\n","        config = AutoConfig.from_pretrained(\n","            config_path,\n","            num_labels=num_labels,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","    else:\n","        config = AutoConfig.from_pretrained(\n","            config_path,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        revision=model_args.model_revision,\n","        use_auth_token=True if model_args.use_auth_token else None,\n","    )\n","    # endregion\n","\n","    # region Dataset preprocessing\n","    # Again, we try to have some nice defaults but don't hesitate to tweak to your use case.\n","    column_names = {col for cols in datasets.column_names.values() for col in cols}\n","    non_label_column_names = [name for name in column_names if name != \"label\"]\n","    if \"sentence1\" in non_label_column_names and \"sentence2\" in non_label_column_names:\n","        sentence1_key, sentence2_key = \"sentence1\", \"sentence2\"\n","    elif \"sentence1\" in non_label_column_names:\n","        sentence1_key, sentence2_key = \"sentence1\", None\n","    else:\n","        if len(non_label_column_names) >= 2:\n","            sentence1_key, sentence2_key = non_label_column_names[:2]\n","        else:\n","            sentence1_key, sentence2_key = non_label_column_names[0], None\n","\n","    if data_args.max_seq_length > tokenizer.model_max_length:\n","        logger.warning(\n","            f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"\n","            f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n","        )\n","    max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)\n","\n","    # Ensure that our labels match the model's, if it has some pre-specified\n","    if \"train\" in datasets:\n","        if not is_regression and config.label2id != PretrainedConfig(num_labels=num_labels).label2id:\n","            label_name_to_id = config.label2id\n","            if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):\n","                label_to_id = label_name_to_id  # Use the model's labels\n","            else:\n","                logger.warning(\n","                    \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n","                    f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"\n","                    \"\\nIgnoring the model labels as a result.\",\n","                )\n","                label_to_id = {v: i for i, v in enumerate(label_list)}\n","        elif not is_regression:\n","            label_to_id = {v: i for i, v in enumerate(label_list)}\n","        else:\n","            label_to_id = None\n","        # Now we've established our label2id, let's overwrite the model config with it.\n","        config.label2id = label_to_id\n","        if config.label2id is not None:\n","            config.id2label = {id: label for label, id in label_to_id.items()}\n","        else:\n","            config.id2label = None\n","    else:\n","        label_to_id = config.label2id  # Just load the data from the model\n","\n","    if \"validation\" in datasets and config.label2id is not None:\n","        validation_label_list = datasets[\"validation\"].unique(\"label\")\n","        for val_label in validation_label_list:\n","            assert val_label in label_to_id, f\"Label {val_label} is in the validation set but not the training set!\"\n","\n","    def preprocess_function(examples):\n","        # Tokenize the texts\n","        args = (\n","            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n","        )\n","        result = tokenizer(*args, max_length=max_seq_length, truncation=True)\n","\n","        # Map labels to IDs\n","        if config.label2id is not None and \"label\" in examples:\n","            result[\"label\"] = [(config.label2id[l] if l != -1 else -1) for l in examples[\"label\"]]\n","        return result\n","\n","    datasets = datasets.map(preprocess_function, batched=True, load_from_cache_file=not data_args.overwrite_cache)\n","    # endregion\n","\n","    with training_args.strategy.scope():\n","        # region Load pretrained model\n","        # Set seed before initializing model\n","        set_seed(training_args.seed)\n","        #\n","        # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n","        # download model & vocab.\n","        if checkpoint is None:\n","            model_path = model_args.model_name_or_path\n","        else:\n","            model_path = checkpoint\n","        model = TFAutoModelForSequenceClassification.from_pretrained(\n","            model_path,\n","            config=config,\n","            cache_dir=model_args.cache_dir,\n","            revision=model_args.model_revision,\n","            use_auth_token=True if model_args.use_auth_token else None,\n","        )\n","        # endregion\n","\n","        # region Optimizer, loss and compilation\n","        optimizer = tf.keras.optimizers.Adam(\n","            learning_rate=training_args.learning_rate,\n","            beta_1=training_args.adam_beta1,\n","            beta_2=training_args.adam_beta2,\n","            epsilon=training_args.adam_epsilon,\n","            clipnorm=training_args.max_grad_norm,\n","        )\n","        if is_regression:\n","            loss_fn = tf.keras.losses.MeanSquaredError()\n","            metrics = []\n","        else:\n","            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","            metrics = [\"accuracy\"]\n","        model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n","        # endregion\n","\n","        # region Convert data to a tf.data.Dataset\n","\n","        tf_data = dict()\n","        max_samples = {\n","            \"train\": data_args.max_train_samples,\n","            \"validation\": data_args.max_val_samples,\n","            \"test\": data_args.max_test_samples,\n","        }\n","        for key in (\"train\", \"validation\", \"test\"):\n","            if key not in datasets:\n","                tf_data[key] = None\n","                continue\n","            if key in (\"train\", \"validation\"):\n","                assert \"label\" in datasets[key].features, f\"Missing labels from {key} data!\"\n","            if key == \"train\":\n","                shuffle = True\n","                batch_size = training_args.per_device_train_batch_size\n","                drop_remainder = True  # Saves us worrying about scaling gradients for the last batch\n","            else:\n","                shuffle = False\n","                batch_size = training_args.per_device_eval_batch_size\n","                drop_remainder = False\n","            samples_limit = max_samples[key]\n","            dataset = datasets[key]\n","            if samples_limit is not None:\n","                dataset = dataset.select(range(samples_limit))\n","            if isinstance(training_args.strategy, tf.distribute.TPUStrategy) or data_args.pad_to_max_length:\n","                logger.info(\"Padding all batches to max length because argument was set or we're on TPU.\")\n","                dataset_mode = \"constant_batch\"\n","            else:\n","                dataset_mode = \"variable_batch\"\n","            data = convert_dataset_for_tensorflow(\n","                dataset,\n","                non_label_column_names,\n","                batch_size=batch_size,\n","                dataset_mode=dataset_mode,\n","                drop_remainder=drop_remainder,\n","                shuffle=shuffle,\n","            )\n","            tf_data[key] = data\n","        # endregion\n","\n","        # region Training and validation\n","        if tf_data[\"train\"] is not None:\n","            callbacks = [SavePretrainedCallback(output_dir=training_args.output_dir)]\n","            model.fit(\n","                tf_data[\"train\"],\n","                validation_data=tf_data[\"validation\"],\n","                epochs=int(training_args.num_train_epochs),\n","                callbacks=callbacks,\n","            )\n","        elif tf_data[\"validation\"] is not None:\n","            # If there's a validation dataset but no training set, just evaluate the metrics\n","            logger.info(\"Computing metrics on validation data...\")\n","            if is_regression:\n","                loss = model.evaluate(tf_data[\"validation\"])\n","                logger.info(f\"Loss: {loss:.5f}\")\n","            else:\n","                loss, accuracy = model.evaluate(tf_data[\"validation\"])\n","                logger.info(f\"Loss: {loss:.5f}, Accuracy: {accuracy * 100:.4f}%\")\n","        # endregion\n","\n","        # region Prediction\n","        if tf_data[\"test\"] is not None:\n","            logger.info(\"Doing predictions on test dataset...\")\n","            predictions = model.predict(tf_data[\"test\"])[\"logits\"]\n","            predicted_class = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)\n","            output_test_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n","            with open(output_test_file, \"w\") as writer:\n","                writer.write(\"index\\tprediction\\n\")\n","                for index, item in enumerate(predicted_class):\n","                    if is_regression:\n","                        writer.write(f\"{index}\\t{item:3.3f}\\n\")\n","                    else:\n","                        item = config.id2label[item]\n","                        writer.write(f\"{index}\\t{item}\\n\")\n","            logger.info(f\"Wrote predictions to {output_test_file}!\")\n","        # endregion\n","\n","    # region Prediction losses\n","    # This section is outside the scope() because it's very quick to compute, but behaves badly inside it\n","    if \"test\" in datasets and \"label\" in datasets[\"test\"].features:\n","        print(\"Computing prediction loss on test labels...\")\n","        labels = datasets[\"test\"][\"label\"]\n","        loss = float(loss_fn(labels, predictions).numpy())\n","        print(f\"Test loss: {loss:.4f}\")\n","    # endregion\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[]}]}